\documentclass{oqireport}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{array}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{adjustbox}


%% Sets page size and margins
\geometry{a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm}

%% Useful packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{cleveref}

\title{Food Production Optimization}
\subtitle{Phase 3 Report}
\author{Edoardo Spigarolo}

\begin{document}

%\begin{itemize}
    %\item link to the (openly accessible?) github
%    \item discuss what has been done in this phase in terms of simulations of the quantum algorithm, how the problem was mapped to the simulator, data pre-processing, hyper-parameter tuning (if applicable)
%    \item specify what (classical) hardware was used for the simulation
%    \item specify what small scale (if applicable) and what real-world data was used, please link the datasets (if not already included in the linked github repository)
%    \item discuss the results of the simulations and compare it to classical benchmarks, how do the results scale in terms of runtime, accuracy, ...
%    \item extrapolate findings to larger scales
%    \item how deal with noise, how did the performance degrade with different levels of noise, embeddings, data pre-processing (if applicable), strategize techniques to do better (error mitigation techniques, circuit depth reduction ...)
%    \item justification to move on to phase 4 (based on previous points, what was done during phase 3? what are the results? why does this lay a good basis for moving on to phase 4 and implement the PoC on QPUs? if needed, re-assess resource estimation for QPU implementation)
%    \item problems encountered (and how did you overcome them?) \\
%    e.g.\ optimising transpilation in IBM machine, problems to differentiate between measurement of classical pre- and postprocessing to simulated quantum computing runtime, ... (only of no repetition of previously mentioned points)

%    \item 4 sections. 1 Setting up the simulation (prerequisites), data, Pre-processing, mapping the problem, hyperparam tuning; 2 results, benchmarking, extrapoilation, noise models; 3 conclusion and discussion, strategizing about noise mitigation, justify move to phase 4, additional discussion of any other problems they encountered and how they can be overcome / circumvented / mitigated; 4th section: further refined impact design

%\end{itemize}

% Instructions to be deleted before submission
\ \\
\ \\
\ \\
\textit{
Instructions and background: 
\begin{itemize}
    \item For each section the envisaged content is specified in italic. All of these comments should be removed before submitting the final document.
    %\item Please be concise and respect the strict page limit of xx pages for the main part of the full proposal (excluding the Methods section, the Team Presentation section and References).
    \item The purpose of the Phase 3 Report is to present and discuss the results from the hardware runs of the quantum solution to the real-world problem as discussed and laid out in the Full Proposal (completed in Phase 2).
    Problems encountered are discussed and solutions / mitigation techniques are proposed to overcome them in future work if needed. 
    The results and the discussion thereof are then used as a basis to look into the differences between what was expected from the Full Proposal, and what was actually achieved. An update on the impact design concludes the report.
    \item The depth of detail expected in this report is such that an outside user could read the report and reproduce the work you have done. It should be in a similar style to that of a scientific paper.
\end{itemize}
}

\newpage

\maketitle

\begin{abstract}
    We formulate the multi-period crop allocation problem as a Constrained Quadratic Model (CQM) and solve it using D-Wave's Advantage quantum processing unit (QPU). Our approach incorporates nutritional value, environmental sustainability, and affordability into a unified optimization framework. Through extensive benchmarking against the classical Gurobi solver, we evaluate quantum performance across two complementary problem formulations. For Formulation A (binary crop allocation with 27 crops), classical Gurobi achieves optimal solutions in under 1.2 seconds, while D-Wave's hybrid solvers demonstrate competitive performance with transparent QPU time accounting. For Formulation B (multi-period rotation with frustrated constraints), we demonstrate practical quantum advantage: our hierarchical decomposition achieves speedups of up to 15$\times$ on small instances and maintains performance advantages on larger problems where classical solvers time out. The QPU achieves 3.80$\times$ higher benefit than timeout-limited Gurobi across 13 rotation scenarios. Pure QPU access time scales linearly with problem size, remaining under 30 seconds for 100-farm instances. Our results establish that quantum advantage is formulation-dependent: quantum annealing excels on frustrated quadratic problems where classical mixed-integer programming becomes computationally prohibitive.
\end{abstract}




\subsubsection*{Relevant SDGs}
\begin{itemize}
    \item \textbf{SDG 2 (Zero Hunger):} Optimizing crop rotation to maximize nutritional output and food security
    \item \textbf{SDG 3 (Good Health):} Enhancing dietary diversity and nutritional quality through multi-objective optimization
    \item \textbf{SDG 12 (Responsible Consumption):} Balancing agricultural output with environmental sustainability and affordability
    \item \textbf{SDG 13 (Climate Action):} Promoting sustainable agricultural practices that reduce environmental impact
    %\item \textbf{SDG 15 (Life on Land):} Encouraging crop diversity and soil health through rotation synergies
    % See if it should be added to impact tool
\end{itemize}

\subsubsection*{Link to GitHub Repository}
    % Instructions to be deleted before submission
    \textit{Please provide the link to the github repository, where your code and datasets for the OQI Use Case are stored.}
    \par
   \textbf{Coming Soon...} 





\section{Setting up on Hardware}

% Instructions to be deleted before submission
\textit{
Describe and discuss what has been done in this phase in terms of running your algorithm on quantum hardware, how the problem was mapped to the QPU, data pre-processing, hyper-parameter tuning (if applicable), post-processing results, etc.
This section should include specification of the quantum hardware used for the runs. 
It also includes describing the small scale (if applicable) and  real-world data used, its source and its relevance in the targeted context. Please link the datasets (if not already included in the linked github repository).
}


\subsection{Introduction}

Phase 3 of this project represents a comprehensive investigation into the practical application of quantum annealing for large-scale agricultural optimization. Building on the theoretical foundations established in Phase 2, we systematically evaluate D-Wave quantum processing units (QPUs) through three complementary research approaches, each using different problem formulations and solution methodologies.

\subsubsection{Experimental Framework}

Our investigation employs two distinct problem formulations evaluated across three complementary studies:

\paragraph{Formulation A: Binary Crop Allocation (Studies 1 \& 2)}
A constrained quadratic model with 27 individual crops, linear benefit objective, and diversity constraints. This represents the baseline agricultural optimization problem where we compare quantum and classical approaches.

\paragraph{Formulation B: Multi-Period Rotation (Study 3)}
An enhanced formulation with 6 aggregated crop families, 3-period temporal horizon, quadratic rotation synergies, and frustrated spatial interactions. This formulation is deliberately designed to challenge classical solvers while remaining QPU-tractable.

\paragraph{Three Complementary Studies:}

\begin{enumerate}
    \item \textbf{Study 1: Hybrid Solver Benchmarking.} We benchmark D-Wave's black-box hybrid solvers from Leap [add ref] against classical Gurobi optimization using Formulation A across multiple scales (10 to 1,000 farms). This establishes baseline quantum performance of the most popular solver offered by DWave [add refs].
    
    \item \textbf{Study 2: Pure QPU Decomposition.} We develop and evaluate seven decomposition strategies (Direct QPU, PlotBased, Multilevel, Louvain, Spectral, Coordinated, CQM-First PlotBased) on Formulation A to address the issue with embedding large problems (add ref to the section where the embedding is discussed). This provides full transparency in quantum versus classical computation time, revealing that pure QPU annealing scales linearly while classical embedding overhead dominates total runtime.
    
    \item \textbf{Study 3: Quantum \textit{Advantage} Demonstration.} Using Formulation B, we show how a specific hybrid algorithm achieves 3.80$\times$ higher benefit than Gurobi across 13 benchmark scenarios in substantially less time (when compared to an arbitrary timeout set to Gurobi).
    
\end{enumerate}



\subsection{Quantum Hardware Platform}

All quantum experiments were conducted on the D-Wave Advantage quantum annealer, accessed via D-Wave's Leap cloud platform [add ref]. The Advantage system represents the current generation of quantum annealing hardware with the following specifications:

\begin{table}[H]
\centering
\caption{D-Wave Advantage System Specifications}
\label{tab:dwave_specs}
\begin{tabular}{ll}
\toprule
\textbf{Parameter} & \textbf{Value} \\
\midrule
Total Qubits & 5,760 \\
Topology & Pegasus P16 \\
Average Qubit Connectivity & 15 neighbors \\
Native Clique Size & 15 to 20 qubits \\
Annealing Time Range & $0.5$ to $2,000\,\mu s$ \\
Programming Thermalization & $1\,ms$ (default) \\
Chain Strength & Auto-scaled (0.9 to 2.0$\times$ max energy) \\
Maximum Problem Variables & $\sim$5,000 (depending on connectivity) \\
\bottomrule
\end{tabular}
\end{table}

The Pegasus topology is critical to our decomposition strategies. Unlike earlier Chimera-based systems, Pegasus provides significantly improved connectivity through a novel crossing architecture. Each qubit connects to 15 neighbors on average, enabling \textbf{native cliques} of 15 to 20 fully connected qubits that can represent logical variables without chain overhead. This property is exploited in our PlotBased and Coordinated decomposition methods, where farm-level subproblems (27 crops per farm $=$ 27 variables) embed with minimal chain breaking.

\subsubsection{QPU Configuration Parameters}

For all pure QPU experiments (excluding hybrid solvers), we employed the following configuration:

\begin{itemize}
    \item \textbf{Number of Reads:} 100 to 500 samples per subproblem (standard setting balancing statistical quality versus QPU time)
    \item \textbf{Annealing Time:} $20\,\mu s$ (default, sufficient for problem class)
    \item \textbf{Chain Strength:} Auto-scaled by D-Wave API based on problem energy scale, typically $1.2$ to $1.8\times$ maximum quadratic coefficient
    \item \textbf{Postprocessing:} Enabled (greedy descent to fix chain breaks and improve energy)
    \item \textbf{Embedding Algorithm:} MinorMiner [add ref] with default timeout.
\end{itemize}

We observed chain break rates consistently below 2\% across all problem instances, indicating that the auto-scaled chain strength was effective. For coordinated decomposition methods requiring boundary consistency, we employed 3 rounds of iterative refinement (add more explaination) between subproblems.

\subsection{Classical Baseline Configuration}

To establish rigorous classical baselines, we employed Gurobi 12.0.3, widely regarded as state-of-the-art for mixed-integer programming. Gurobi implements decades of algorithmic development including:

\begin{itemize}
    \item Branch-and-bound with advanced node selection strategies
    \item Cutting plane generation (Gomory, clique, flow cover, MIR cuts)
    \item Sophisticated presolve reductions and symmetry detection
    \item Parallel MIP search with concurrent optimizers
    \item Primal heuristics for rapid feasible solution discovery
\end{itemize}

\textbf{Gurobi Configuration:} We configured Gurobi 12.0.3 with timeout values adapted to the experiment type: \textbf{600 seconds} for main quantum advantage benchmarks (Study III hierarchical methods), \textbf{100 seconds} for standard baseline comparisons (Studies I and II), and \textbf{60 seconds} for QPU native validation experiments. These timeouts represent practical upper bounds for different agricultural planning contextsâ€”from interactive decision support (60-100s) to comprehensive seasonal planning (600s). The MIP gap tolerance was set to 1\%, allowing early termination if the current solution was provably within 1\% of optimal. We enabled MIP Focus mode 1 (prioritize feasibility) and allowed multi-threading across all available CPU cores. Aggressive presolve and cutting plane generation were enabled by default.

\textbf{Computational Environment:} All classical experiments were conducted on an Intel Core i7-12700H (14 cores, 20 threads) with 16 GB RAM to ensure reproducibility. Classical solve times reported are wall-clock times including all preprocessing. 
% QPU times are separated into: (1) embedding time (classical), (2) pure QPU access time (quantum), and (3) postprocessing time (classical).

\subsection{Problem Data and Scenarios}

\subsubsection{Food and Crop Database}

Our optimization framework uses real-world nutritional, economic, and environmental data for 27 common crops across 5 food groups:

\begin{table}[H]
\centering
\caption{Crop Database Structure (27 crops, 5 food groups)}
\label{tab:crop_database}
\small
\begin{tabular}{p{3cm}p{8cm}l}
\toprule
\textbf{Food Group} & \textbf{Crops Included} & \textbf{Count} \\
\midrule
Animal Protein & Beef, Chicken, Egg, Lamb, Pork & 5 \\
Fruits & Apple, Avocado, Banana, Durian, Guava, Mango, Orange, Papaya, Watermelon & 9 \\
Legumes & Chickpeas, Peanuts, Tempeh, Tofu & 4 \\
Staples & Corn, Potato & 2 \\
Vegetables & Cabbage, Cucumber, Eggplant, Long bean, Pumpkin, Spinach, Tomatoes & 7 \\
\bottomrule
\end{tabular}
\end{table}

Each crop $c$ is characterized by a composite benefit score $B_c$ computed from five weighted components:

\begin{equation}
B_c = w_{nv} \cdot v_{nv,c} + w_{nd} \cdot v_{nd,c} - w_{ei} \cdot v_{ei,c} + w_{af} \cdot v_{af,c} + w_{su} \cdot v_{su,c}
\end{equation}

where:

\textbf{Note: parentheses still need to be clarified by gain}


\begin{itemize}
    \item $v_{nv,c}$: Nutritional value (vitamins, minerals, fiber content)
    \item $v_{nd,c}$: Nutrient density (calories per kg, protein content)
    \item $v_{ei,c}$: Environmental impact (??), \textbf{negatively weighted}
    \item $v_{af,c}$: Affordability (inverse cost per kg)
    \item $v_{su,c}$: Sustainability score (soil health impact, biodiversity support, carbon footprint, water usage, land acidification, ...)
\end{itemize}

Weights are normalized such that $\sum_i |w_i| = 1.0$. For this study, we used $w_{nv} = 0.25$, $w_{nd} = 0.20$, $w_{ei} = 0.20$, $w_{af} = 0.20$, $w_{su} = 0.15$, reflecting a balanced multi-objective optimization.


\subsubsection{Problem Scales and Test Scenarios}

We evaluated solver performance across two allocation paradigms with multiple problem scales:

\textbf{Test Configuration 1: Patch-Level Allocation (Formulation A)}
\begin{itemize}
    \item \textbf{Scales:} 10, 15, 25, 50, 100, 200, 1,000 patches
    \item \textbf{Binary Variables:} $n = |\mathcal{F}| \times |\mathcal{C}| = 27f$ (e.g., 27,000 for 1,000 farms)
    \item \textbf{Constraints:} One crop per farm, food group diversity (5 groups with min/max bounds), area capacity
\end{itemize}

\textbf{Test Configuration 2: Multi-Period Rotation (Formulation B)}
\begin{itemize}
    \item \textbf{Temporal Dimension:} 3-period rotation planning (e.g., period 1, period 2, period 3)
    \item \textbf{Variables:} $n = |\mathcal{F}| \times |\mathcal{C}| \times T = 81f$ (3 periods)
    \item \textbf{Additional Constraints:} No crop repetition in consecutive periods, rotation synergies (e.g., legumes improve soil nitrogen for subsequent crops)
    \item \textbf{Purpose:} Tests quantum performance on temporally coupled problems where classical solvers exhibit computational barriers
\end{itemize}


\subsection{Problem Formulation: Common Definitions}



Let's first define the common sets and indices:
\begin{itemize}
    \item ${F}$: Set of farms with land availability $L_f$ for $f \in {F}$
    \item $G$: Set of crop families (or groups), indexed by $g$. In our case, $|G|=6$
    \item ${F}$: Set of farms with land availability $L_f$ for $f \in {F}$
    \item ${C}$: Set of crops 
    \item ${G}$: Set of food groups/families

\end{itemize}






\subsection{Problem Formulation: Binary Crop Allocation CQM}

The core optimization problem is formulated as a Constrained Quadratic Model suitable for both Leap Hybrid Solvers. For clarity, we present the binary formulation used in Phase 3 benchmarking.

\subsubsection{Decision Variables}

\begin{itemize}
    \item $Y_{f,c} \in \{0,1\}$: Binary variable indicating whether crop $c$ is planted on farm/patch $f$
    \item $U_{c} \in \{0,1\}$: Binary variable indicating whether crop $c$ is selected on at least one farm (used for diversity constraints)
\end{itemize}

\subsubsection{Objective Function}

Maximize total area-weighted benefit normalized by total available land:

\begin{equation}
\max \quad Z = \frac{1}{A_{total}} \sum_{f \in \mathcal{F}} \sum_{c \in \mathcal{C}} L_f \cdot B_c \cdot Y_{f,c}
\end{equation}

where:
\begin{itemize}
    \item $A_{total} = \sum_{f \in \mathcal{F}} L_f$ is the total land area
    \item $B_c$ is the composite benefit score for crop $c$
\end{itemize}

\subsubsection{Constraints}
\begin{itemize}

\item \textbf{ Plot Assignment:} Each farm/patch is assigned to at most one crop:
\begin{equation}
\sum_{c \in \mathcal{C}} Y_{f,c} \leq 1 \quad \forall f \in \mathcal{F}
\end{equation}

\item \textbf{ Crop Selection Indicator:} If any farm plants crop $c$, then $U_c = 1$:
\begin{equation}
\sum_{f \in \mathcal{F}} Y_{f,c} \geq U_c \quad \forall c \in \mathcal{C}
\end{equation}

\item \textbf{ Food Group Diversity:} Ensure minimum and maximum number of unique crops per food group $g$:
\begin{equation}
m_g \leq \sum_{c \in G_g} U_c \leq M_g \quad \forall g \in \mathcal{G}
\end{equation}


where $G_g \subseteq \mathcal{C}$ is the set of crops belonging to food group $g$.

\item \textbf{ Minimum/Maximum Crop Area:} Total area planted with crop $c$ must satisfy bounds:
\begin{equation}
a^{min}_c \cdot U_c \leq \sum_{f \in \mathcal{F}} L_f \cdot Y_{f,c} \leq a^{max}_c \cdot U_c \quad \forall c \in \mathcal{C}
\end{equation}

\end{itemize}


% \subsubsection{Multi-Period Extension for Rotation Analysis}

% For the 3-period rotation test configuration, we extend variables to $Y_{f,c,t}$ (crop $c$ on farm $f$ in period $t \in \{1,2,3\}$) and add rotation constraints:

% \textbf{(R1) No Consecutive Repetition:}
% \begin{equation}
% Y_{f,c,t} + Y_{f,c,t+1} \leq 1 \quad \forall f \in \mathcal{F}, c \in \mathcal{C}, t \in \{1,2\}
% \end{equation}

% \textbf{(R2) Rotation Synergy Bonuses:} Add quadratic objective terms for beneficial rotations (e.g., legumes followed by corn):
% \begin{equation}
% Z_{rotation} = \sum_{f,t} \sum_{(c_1,c_2) \in \text{Synergies}} \beta_{c_1,c_2} \cdot Y_{f,c_1,t} \cdot Y_{f,c_2,t+1}
% \end{equation}

% where $\beta_{c_1,c_2} > 0$ quantifies the agronomic benefit of planting crop $c_2$ after $c_1$.


\subsection{Problem Formulation B: Hierarchical Multi-Period Rotation}
\label{subsec:formulation_b}



\subsection{Decision Variable}
Let $Y_{f,c,t}$ be a binary variable:
\[
    Y_{f,c,t} = \begin{cases} 
    1 & \text{if crop } c \in C \text{ is planted on farm } f \in F \text{ in period } t \in T \\
    0 & \text{otherwise}
    \end{cases}
\]

\subsection{Objective Function}

The objective is to maximize the total normalized benefit:
\begin{equation}
\text{maximize} \quad \left( \text{Benefit} + \text{Temporal} + \text{Spatial} - \text{Penalty} + \text{Diversity} \right)
\end{equation}

\subsubsection{Base Benefit (Linear)}
This term represents the intrinsic value of planting a crop, weighted by the farm's area:
\begin{equation}
\text{Benefit} = \sum_{f \in F} \sum_{c \in C} \sum_{t \in T} \frac{B_c \cdot L_f}{A_{\text{total}}} \cdot Y_{f,c,t}
\end{equation}
where $B_c$ is the benefit of crop $c$, $L_f$ is the area of farm $f$, and $A_{\text{total}}$ is the total area of all farms.

\subsubsection{Temporal Synergy with Frustrated Rotations (Quadratic)}
This term models the effect of crop rotation on the same farm over consecutive periods, incorporating agronomic interactions:
\begin{equation}
\text{Temporal} = \gamma_{\text{rot}} \sum_{f \in F} \sum_{t=2}^{T} \sum_{c_1 \in C} \sum_{c_2 \in C} \frac{L_f}{A_{\text{total}}} \cdot R_{c_1,c_2} \cdot Y_{f,c_1,t-1} \cdot Y_{f,c_2,t}
\end{equation}

\paragraph{Rotation Matrix Definition.}
The rotation matrix $R \in \mathbb{R}^{|C| \times |C|}$ encodes agronomic interactions:
\begin{equation}
R_{c_1,c_2} = \begin{cases}
-\beta \cdot 1.5 & \text{if } c_1 = c_2 \text{ (monoculture penalty)} \\
\text{Unif}(\beta \cdot 1.2, \beta \cdot 0.3) & \text{with prob. } p_{\text{frust}} \text{ (disease/competition)} \\
\text{Unif}(0.02, 0.20) & \text{otherwise (beneficial rotation)}
\end{cases}
\end{equation}

\paragraph{Parameters.}
\begin{itemize}
    \item $\beta \in [-0.8, -1.5]$: Negative synergy strength
    \item $p_{\text{frust}} \in [0.70, 0.88]$: Frustration ratio (70\%--88\% negative edges)
    \item $\gamma_{\text{rot}}$: Temporal coupling strength
\end{itemize}

\paragraph{Agronomic Justification.}
\begin{itemize}
    \item \textbf{Monoculture penalty} ($c_1 = c_2$): Same crop depletes specific nutrients and builds up soil pathogens
    \item \textbf{Disease carryover}: Pathogens persist in soil (e.g., tomato $\to$ potato with late blight)
    \item \textbf{Allelopathy}: Some plants inhibit others chemically (e.g., certain brassicas)
    \item \textbf{Beneficial rotations}: Nitrogen-fixing legumes improve soil for subsequent grains
\end{itemize}

\subsubsection{Spatial Synergy with Neighbor Interactions (Quadratic)}
This term models the effect of planting crops on neighboring farms in the same period. Farms are arranged on a grid and interact with their $k=4$ nearest neighbors:
\begin{equation}
\text{Spatial} = \gamma_{\text{spat}} \sum_{(f_1, f_2) \in \mathcal{E}} \sum_{t \in T} \sum_{c_1 \in C} \sum_{c_2 \in C} \frac{S_{c_1,c_2}}{A_{\text{total}}} \cdot Y_{f_1,c_1,t} \cdot Y_{f_2,c_2,t}
\end{equation}

\paragraph{Spatial Components.}
\begin{itemize}
    \item $\mathcal{E}$: Edge set of $k$-nearest neighbor graph
    \item $S_{c_1,c_2} = 0.3 \cdot R_{c_1,c_2}$: Spatial compatibility matrix (dampened rotation matrix)
    \item $\gamma_{\text{spat}} = 0.5 \gamma_{\text{rot}}$: Spatial coupling strength (typically weaker than temporal)
\end{itemize}

\paragraph{Ecological Interpretation.}
This models cross-farm interactions:
\begin{itemize}
    \item \textbf{Positive effects:} Pollination services, beneficial insect sharing, wind breaks, microclimate modification
    \item \textbf{Negative effects:} Pest and disease spread across farm boundaries, resource competition (water, light)
\end{itemize}

\subsubsection{Key Design Principles}

\begin{enumerate}
    \item \textbf{Unified synergy matrix:} Both temporal and spatial terms use variants of the same $R$ matrix, ensuring consistency in modeling agronomic interactions across scales.
    
    \item \textbf{Scale hierarchy:} The relationship $\gamma_{\text{spat}} = 0.5\gamma_{\text{rot}}$ reflects that spatial effects between farms are typically weaker than within-farm temporal rotations.
    
    \item \textbf{Dampening factor:} The $0.3$ multiplier in $S = 0.3R$ accounts for reduced interaction strength across farm boundaries compared to sequential plantings on the same soil parcel.
    
    \item \textbf{Normalization:} Both temporal and spatial terms use $A_{\text{total}}$ normalization to ensure scale-invariant optimization, with spatial effects further modulated by the dampening coefficient.
\end{enumerate}

This formulation captures the multi-scale nature of agricultural systems: within-farm temporal dynamics (crop rotation effects) and between-farm spatial spillovers (ecological interactions), all grounded in the same underlying agronomic compatibility relationships encoded in $R$.

\paragraph{4. One-Hot Penalty (Quadratic)}
This term penalizes deviations from planting exactly one crop per farm-period, enforcing a "soft" one-hot constraint.
\[
    \text{Penalty} = \lambda_{oh} \sum_{f \in F} \sum_{t \in T} \left( \left(\sum_{c \in C} Y_{f,c,t}\right) - 1 \right)^2
\]
where $\lambda_{oh}$ is the penalty coefficient.

\paragraph{5. Diversity Bonus (Linear)}
This term rewards planting a crop on a farm at least once during the planning horizon.
\[
    \text{Diversity} = \lambda_{div} \sum_{f \in F} \sum_{c \in C} \mathbb{I}\left(\sum_{t \in T} Y_{f,c,t} > 0\right)
\]
where $\lambda_{div}$ is the diversity bonus coefficient and $\mathbb{I}(\cdot)$ is the indicator function. This is typically linearized in Gurobi.

\subsection{Constraints}
\begin{enumerate}
    \item \textbf{Maximum Crops (Soft Constraint):} To allow for some flexibility, the model constrains the number of crops per farm-period to be at most 2.
    \[ \forall f \in F, \forall t \in T: \quad \sum_{c \in C} Y_{f,c,t} \le 2 \]
    \item \textbf{Minimum Crops (Soft Constraint):} Ensures at least one crop is planted.
    \[ \forall f \in F, \forall t \in T: \quad \sum_{c \in C} Y_{f,c,t} \ge 1 \]
\end{enumerate}

\textbf{Note:} Rotation behavior (avoiding monoculture) is enforced through the temporal synergy objective term with $R_{c,c} < 0$ (monoculture penalty), rather than a hard constraint. This allows the optimization to naturally discourage same-crop consecutive planting while maintaining a smoother objective landscape.


% \subsubsection{Objective Function}

% The objective function maximizes a composite score consisting of five components, carefully designed to balance agricultural productivity, rotation benefits, spatial synergies, crop diversity, and constraint satisfaction. The complete objective is:
% \begin{equation}
% \mathcal{O} = \mathcal{O}_{\text{benefit}} + \mathcal{O}_{\text{rotation}} + \mathcal{O}_{\text{spatial}} + \mathcal{O}_{\text{diversity}} - \mathcal{O}_{\text{penalty}}
% \label{eq:objective}
% \end{equation}

% The first component rewards growing high-value crops, weighted by land area and normalized by total area to ensure comparability across problem sizes:
% \begin{equation}
% \mathcal{O}_{\text{benefit}} = \sum_{f \in \mathcal{F}} \sum_{c \in \mathcal{C}} \sum_{t \in \mathcal{T}} \frac{B_c \cdot L_f}{A_{\text{total}}} \cdot Y_{f,c,t}
% \end{equation}

% The second component captures temporal rotation synergies, the agricultural insight that certain crop sequences are beneficial (e.g., legumes before grains provide nitrogen fixation) while others are harmful (e.g., repeated planting of the same crop depletes specific soil nutrients):
% \begin{equation}
% \mathcal{O}_{\text{rotation}} = \sum_{f \in \mathcal{F}} \sum_{t=2}^{T} \sum_{c_1, c_2 \in \mathcal{C}} \frac{\gamma_{\text{rot}} \cdot R_{c_1, c_2} \cdot L_f}{A_{\text{total}}} \cdot Y_{f,c_1,t-1} \cdot Y_{f,c_2,t}
% \end{equation}

% This term is inherently quadratic, involving products of decision variables from consecutive time periods. The rotation weight $\gamma_{\text{rot}} = 0.2$ balances rotation benefits against direct crop value. The rotation matrix $R$ includes a strong self-penalty ($R_{c,c} = -1.2$) to discourage monoculture, alongside a mixture of antagonistic and synergistic crop pairs.

% The third component models spatial interactions between neighboring farms, reflecting real-world effects such as pest management, pollination corridors, and shared irrigation infrastructure:
% \begin{equation}
% \mathcal{O}_{\text{spatial}} = \sum_{(f_1, f_2) \in \mathcal{E}} \sum_{t \in \mathcal{T}} \sum_{c_1, c_2 \in \mathcal{C}} \frac{\gamma_{\text{spatial}} \cdot R_{c_1, c_2} \cdot 0.3}{A_{\text{total}}} \cdot Y_{f_1,c_1,t} \cdot Y_{f_2,c_2,t}
% \end{equation}

% where $\mathcal{E}$ denotes the edge set of the spatial neighbor graph. This term is also quadratic, coupling decisions across different farms and creating long-range correlations that make the problem particularly challenging for decomposition approaches. The spatial weight $\gamma_{\text{spatial}} = 0.1$ is set lower than the rotation weight, reflecting the empirical observation that temporal rotation effects typically dominate spatial neighbor effects in practice.

% The fourth component provides a diversity bonus, encouraging farms to utilize multiple crop families across the rotation cycle rather than specializing in a single high-value crop:
% \begin{equation}
% \mathcal{O}_{\text{diversity}} = \sum_{f \in \mathcal{F}} \sum_{c \in \mathcal{C}} \beta_{\text{div}} \cdot \mathbf{1}\left[\sum_{t \in \mathcal{T}} Y_{f,c,t} > 0\right]
% \end{equation}

% The indicator function awards a bonus of $\beta_{\text{div}} = 0.15$ for each crop family used at least once on each farm. This promotes agricultural resilience and reduces the risk associated with monoculture strategies.

% Finally, a soft penalty term enforces the constraint that each farm should plant exactly one crop per period:
% \begin{equation}
% \mathcal{O}_{\text{penalty}} = \sum_{f \in \mathcal{F}} \sum_{t \in \mathcal{T}} \lambda_{\text{penalty}} \cdot \left(\sum_{c \in \mathcal{C}} Y_{f,c,t} - 1\right)^2
% \end{equation}

% With $\lambda_{\text{penalty}} = 3.0$, this quadratic penalty strongly discourages solutions that leave farms idle or assign multiple crops to the same farm-period combination. A hard constraint limits the number of crops per farm-period to at most 2, providing a feasibility bound that the soft penalty then tightens.

\subsubsection{Justification and Calibration of Model Parameters}

The rotation synergy matrix $R \in \mathbb{R}^{6 \times 6}$ and spatial interaction terms in our formulation require careful calibration to balance agronomic realism with computational tractability. We ground our parameter choices in both empirical agricultural research and established optimization modeling practices.

\paragraph{Rotation Synergy Effects}

Our rotation benefits are calibrated to match empirical findings from large-scale meta-analyses. Recent synthesis of 3,663 paired field-trial observations across six continents shows that crop rotations increase subsequent crop yields by 16-23\% on average compared to monoculture, with legume pre-crops providing the largest benefits \cite{mudare2025crop}. We model these effects through positive entries in $R_{c,c'}$ for beneficial crop sequences (e.g., legume $\to$ cereal), drawn from $\text{Unif}(0.02, 0.25)$ to capture the observed range of rotation advantages.

For monoculture penalties, we set $R_{c,c} = -\beta \cdot 1.5$ where $\beta \in [-0.8, -1.5]$, yielding effective penalties in the range $[-1.2, -2.25]$. With our rotation weight $\gamma = 0.2$, this produces an objective penalty of approximately 24\% for continuous monoculture ($0.2 \times 1.2 = 0.24$), consistent with documented economic disadvantages of monoculture systems that compound yield losses (10-15\%), increased pest pressure (5-10\%), soil degradation (3-5\%), and higher input costs (2-5\%) \cite{preissel2015magnitude, reckling2018grain}.

The agronomic justifications for specific rotation effects include:
\begin{itemize}
    \item \textbf{Monoculture penalty} ($c = c'$): Continuous cultivation of the same crop depletes specific soil nutrients, allows pest and pathogen populations to build up, and may involve allelopathic effects from residue accumulation \cite{kirkegaard2014magnitude}.
    
    \item \textbf{Disease carryover}: Pathogens persist in soil when crops from the same botanical family are grown in succession (e.g., tomato $\to$ potato), modeled through the frustration ratio $p_{\text{frust}} \in [0.70, 0.88]$ that determines the proportion of negative synergy values in $R$.
    
    \item \textbf{Allelopathy}: Some crops chemically inhibit the growth of subsequent crops through root exudates or decomposing residues, captured by negative $R_{c,c'}$ entries between antagonistic species.
    
    \item \textbf{Beneficial rotations}: Nitrogen-fixing legumes improve soil fertility for subsequent grain crops through biological nitrogen fixation (20-40 kg N/ha), reducing fertilizer requirements by 40-45\% while maintaining yields \cite{cernay2018preceding, zhao2022global}.
\end{itemize}

\paragraph{Spatial Adjacency Effects}

The spatial neighbor interaction term represents a methodological contribution that bridges conflicting evidence in the literature. Traditional rotation planning imposes hard constraints forbidding same-family crops on adjacent plots \cite{ballot2023first}
, based on the resource concentration hypothesis that larger or more connected host plant stands recruit more pests per plant \cite{root1973organization}. However, recent large-scale empirical studies across 14 pest species and 20,000 field-years found that pest severity is often independent of field size, with no consistent evidence that spatial concentration worsens pest impacts %\cite{karp2018crop}.

Rather than adopting either extreme---strict prohibition or complete neglect of spatial effects---we implement a \emph{dampened spatial interaction term} with coupling strength $\gamma_s = 0.5\gamma$ and compatibility matrix $S_{c,c'} = 0.3 \cdot R_{c,c'}$. This soft penalty approach:

\begin{enumerate}
    \item \textbf{Respects agronomic wisdom} encoded in traditional rotation constraints while acknowledging empirical uncertainty about effect magnitudes.
    
    \item \textbf{Provides optimization flexibility} to weigh spatial risks against yield and rotation objectives, acting as a regularization term that promotes diversity without over-constraining the solution space.
    
    \item \textbf{Scales appropriately} with the problem structure: the combined dampening ($0.5 \times 0.3 = 0.15$) means spatial adjacency effects are approximately 15\% of temporal rotation effects, reflecting that edge effects operate on smaller spatial scales than whole-field succession effects, pest pressure builds gradually within seasons (unlike year-to-year carryover), and modern pest management can partially mitigate spatial concentration.
    
    \item \textbf{Enables calibration} through the tunable parameter $\gamma_s$, which can be adjusted for regional pest pressure or used in robust optimization across uncertainty ranges---a capability impossible with binary adjacency constraints.
\end{enumerate}

The spatial term is scaled by cell area $L_f$ to maintain dimensional consistency with the temporal rotation term. While spatial effects operate primarily through edge interactions, this scaling accounts for interface length between adjacent cells (proportional to $\sqrt{L_f}$ for square cells) and ensures that spatial penalties contribute to the objective function commensurate with area-weighted rotation benefits.

\paragraph{Temporal Horizon and Multi-Period Structure}

Our three-period planning horizon ($T = 3$) balances several considerations. Empirical evidence shows that rotation benefits strengthen over time, with long-term experiments (9-50 years) demonstrating cumulative soil health improvements and pest suppression \cite{mudare2025crop}. However, longer planning horizons increase computational complexity exponentially while introducing greater uncertainty in future crop prices and environmental conditions. The three-year window captures the primary rotation cycle for most cropping systems (e.g., corn-soybean-wheat or legume-cereal-legume sequences) while remaining computationally tractable.

\paragraph{Parameter Summary and Validation}

Table~\ref{tab:parameters} summarizes our model parameters alongside their literature-supported ranges. Our choices fall within established bounds from both agronomic field trials and published optimization models \cite{haneveld2005crop, liang2023designing}. The 24\% effective monoculture penalty, 15\% spatial effect dampening, and 16-25\% rotation benefits collectively create a realistic but computationally challenging optimization landscape that reflects the multi-objective trade-offs facing agricultural decision-makers.

\begin{table}[h]
\centering
\caption{Model parameters and literature validation}
\label{tab:parameters}
\begin{tabular}{lccc}
\hline
\textbf{Parameter} & \textbf{Our Value} & \textbf{Literature Range} & \textbf{Source} \\
\hline
Rotation weight $\gamma$ & 0.2 & 0.1--0.3 & \cite{preissel2015magnitude} \\
Monoculture penalty & 24\% & 15--30\% & \cite{kirkegaard2014magnitude} \\
Legume benefit & 16--25\% & 16--23\% & \cite{mudare2025crop} \\
Spatial dampening & 0.15 & 0.1--0.2 & This work \\
Frustration ratio & 0.70--0.88 & 0.50--0.80 & \cite{lucas2014ising} \\
Planning horizon $T$ & 3 years & 2--5 years & \cite{haneveld2005crop} \\
\hline
\end{tabular}
\end{table}

Importantly, our formulation uses a \emph{linear} objective contribution for rotation effects (Equation~25), not an exponential yield multiplier. This follows standard practice in agricultural optimization models where penalties are added to the objective function rather than applied multiplicatively to crop yields \cite{cai2011dynamic}. The distinction is critical: a rotation penalty of $-1.2$ reduces the objective contribution by $0.2 \times 1.2 = 24\%$ in our linear formulation, not by $\exp(-1.2) \approx 70\%$ as would occur in exponential crop growth models used for long-term simulation \cite{keating2003overview}.

This parameter calibration ensures our benchmark instances represent realistic agricultural planning scenarios while exhibiting the structural complexity---quadratic interactions, constraint frustration, and long-range correlations---that make quantum optimization potentially advantageous over classical approaches.




\subsection{Conversion to Quantum-Annealer-Compatible Formats}

To solve on pure QPU hardware (without hybrid solvers), we convert the CQM constraints to penalty terms, yielding an unconstrained Binary Quadratic Model (BQM). The general transformation is:
\begin{equation}
\min \quad E(Y) = -Z(Y) + \sum_{i} \lambda_i \cdot P_i(Y)
\end{equation}
where $-Z(Y)$ is the negated objective, $P_i(Y)$ are quadratic penalty terms for constraint violations, and $\lambda_i$ are penalty weights. The result is expressed in standard BQM form:
\begin{equation}
E(\mathbf{x}) = \sum_{i} h_i x_i + \sum_{i<j} J_{ij} x_i x_j
\end{equation}
where $h_i$ are linear biases and $J_{ij}$ are quadratic couplings.

\subsubsection{BQM for Formulation A (Binary Crop Allocation)}

For Formulation A with variables $Y_{f,c}$, the BQM components are:

\textbf{Linear biases} (from objective):
\begin{equation}
h_{(f,c)} = -\frac{L_f \cdot B_c}{A_{\text{total}}}
\end{equation}

\textbf{Quadratic couplings} (from one-hot constraint penalty):
\begin{equation}
J_{(f,c_1),(f,c_2)} = 2\lambda_{\text{oh}} \quad \forall c_1 \neq c_2
\end{equation}

The plot assignment constraint $\sum_c Y_{f,c} \leq 1$ becomes the penalty $P(Y) = \lambda_{\text{oh}} \left(\sum_c Y_{f,c} - 1\right)^2$, which expands to introduce the quadratic couplings above.

\textbf{Problem size:} $n = F \cdot C$ variables with $F \cdot \binom{C}{2}$ quadratic terms.

\subsubsection{BQM for Formulation B (Multi-Period Rotation)}

For Formulation B with variables $Y_{f,c,t}$, the BQM includes additional terms from temporal and spatial synergies:

\textbf{Linear biases}:
\begin{equation}
h_{(f,c,t)} = -\frac{B_c \cdot L_f}{A_{\text{total}}} + 2\lambda_{\text{oh}}
\end{equation}

\textbf{Quadratic couplings}:
\begin{align}
J_{(f,c_1,t),(f,c_2,t+1)} &= -\gamma_{\text{rot}} \cdot \frac{R_{c_1,c_2} \cdot L_f}{A_{\text{total}}} && \text{(rotation synergy)} \\
J_{(f_1,c_1,t),(f_2,c_2,t)} &= -\gamma_{\text{spat}} \cdot \frac{S_{c_1,c_2}}{A_{\text{total}}} && \text{(spatial coupling, } (f_1,f_2) \in \mathcal{E} \text{)} \\
J_{(f,c_1,t),(f,c_2,t)} &= 2\lambda_{\text{oh}} && \text{(one-hot penalty, } c_1 \neq c_2 \text{)}
\end{align}

\textbf{Problem size:} $n = F \cdot C \cdot T$ variables. For a typical instance (5 farms, 6 crop families, 3 periods): $n = 90$ variables with approximately 765 quadratic terms.

\textbf{Penalty weight selection:} We set $\lambda_{\text{oh}} = 3.0$ to ensure constraint satisfaction while preserving objective structure. If too small, constraints are violated; if too large, the solver cannot explore the true objective landscape.


\subsubsection{Embedding on Pegasus Topology}

\textbf{Embedding Challenges and Necessity of Problem Decomposition}

The limited connectivity of quantum annealing hardware necessitates embedding logical problem graphs onto the physical qubit topology. While D-Wave's Pegasus architecture offers improved connectivity compared to its predecessor Chimera topology, significant embedding challenges remain for densely connected optimization problems. Research demonstrates a clear correlation between average chain length and the relative errors of solutions sampled, underscoring embedding quality's critical influence on quantum annealing performance~\cite{prxquantum2040322}.

Recent studies establish clear thresholds beyond which direct embedding becomes infeasible, making decomposition strategies essential:

\textbf{Direct Embedding Limitations:}
The embedding of fully connected graphs incurs a quadratic space overhead and thus a significant overhead in the time to solution~\cite{prxquantum2040322,qute202300104}. For Pegasus topology, while algorithms like Clique-Based MinorMiner can embed cliques up to approximately 185 nodes, standard MinorMiner fails to embed even medium-density graphs on 175--180 nodes~\cite{zbinden2020embedding,qute202300104}. For a Pegasus graph with 100\% yield, the largest embeddable complete graph is $K_{150}$ with chain length of 14~\cite{boothby2020next}, though typical QPUs achieve only $\sim$95\% yield, further reducing embeddable problem sizes.

Zbinden et al.~\cite{zbinden2020embedding} systematically evaluated embedding algorithms across different problem densities, finding that direct embedding success rates drop dramatically for graphs with edge densities exceeding 0.2 and node counts above 180. Our farm-level problems with 150+ variables and high connectivity (representing constraints between multiple parcels, crops, and time periods) fall well outside this direct embedding success range.

\textbf{Time-to-Solution Overhead:}
Large-scale quantum Monte Carlo simulations suggest that embedding schemes impose a polynomial time-to-solution overhead~\cite{prxquantum2040322}, with large penalty terms tending to affect quantum annealing hardware performance, though weak constraints risk chain breaks that lose logical information~\cite{choi2008minor}. This fundamental trade-off between constraint strength and solution quality further motivates decomposition approaches that reduce problem complexity.

The BQM must be embedded onto the physical qubit connectivity graph. D-Wave's MinorMiner algorithm~\cite{cai2014practical} finds a minor embedding by mapping logical variables to chains of physical qubits. \textbf{Chain strength} couples chained qubits to ensure they remain in the same state during annealing.

\textbf{Key Metrics:}
\begin{itemize}
    \item \textbf{Embedding Time:} Classical overhead for finding the embedding (typically 0.1 to 100 seconds depending on problem connectivity). The HUBO formulation performs slightly better than augmented Lagrangian methods for constrained problems, but its scalability in terms of embeddability in the quantum chip is worse~\cite{qute202300104}, highlighting the importance of formulation choice on embedding feasibility.
    \item \textbf{Chain Length:} Average number of physical qubits per logical variable (lower is better; native cliques have chain length 1). Variables with more or larger couplings require stronger constraints than those with fewer couplings, and one wants to use constraints as small as possible because large penalty terms affect performance~\cite{choi2008minor}.
    \item \textbf{Chain Break Rate:} Fraction of samples where chained qubits disagree (should be $<$2\% for reliable results). Minor embedding introduces new types of errors due to its approximate nature, and quantum annealing correction schemes can improve performance by efficiently decoding errors when their density does not exceed the per-site percolation threshold~\cite{vinci2016nested}.
\end{itemize}

\textbf{Decomposition as the Only Viable Strategy:}

Given these constraints, our hierarchical decomposition approach becomes not merely advantageous but necessary. Results demonstrate that standard analog quantum annealing hardware is at a disadvantage compared to classical digital annealers for fully-connected problems, highlighting the need to develop new approaches that overcome fundamental challenges~\cite{prxquantum2040322,albash2018adiabatic}. Our strategy of decomposing the 150-variable farm problem into multiple 27-variable subproblems ensures:

\begin{enumerate}
    \item \textbf{Guaranteed Embeddability:} Subproblems remain well within the direct embedding success range
    \item \textbf{Optimal Chain Lengths:} Smaller, sparser subproblems achieve near-native chain lengths ($\leq 1.2$)
    \item \textbf{Minimal Embedding Overhead:} Fast embedding times ($<0.5$ seconds per subproblem) enable efficient iterative refinement
    \item \textbf{Reduced Chain Break Rates:} Shorter chains and lower connectivity yield more reliable sampling
\end{enumerate}

\textbf{Observation:} For our farm-level subproblems (27 variables), we consistently achieved chain length $\leq 1.2$ and embedding time $<0.5$ seconds, validating the suitability of Pegasus topology for our decomposition strategies. These metrics place our subproblems firmly within the ``sweet spot'' identified by embedding algorithm research, where direct embedding is both feasible and efficient.


\begin{algorithm}
\caption{Direct QPU Embedding}
\begin{algorithmic}[1]
\Require CQM with variables $\mathcal{V}$, constraints $\mathcal{C}$
\Ensure Solution $\mathbf{x}$ or failure
\State Convert CQM to BQM: $\text{BQM} \leftarrow \text{cqm\_to\_bqm}(\text{CQM}, \lambda)$
\State Build source graph $G_s = (\mathcal{V}, E_s)$ from BQM quadratic terms
\State Get QPU target graph $G_t = (Q, E_t)$ from Pegasus topology
\State Find embedding: $\phi: \mathcal{V} \rightarrow 2^Q$ using minorminer
\If{embedding found within timeout}
    \State Sample: $\mathbf{x} \leftarrow \text{QPU.sample}(\text{BQM}, \phi, n_{\text{reads}})$
    \State \Return best feasible solution
\Else
    \State \Return FAIL (problem too large)
\EndIf
\end{algorithmic}
\end{algorithm}

\paragraph{Complexity}
\begin{itemize}
\item \textbf{Time}: $O(T_{\text{embed}} + n_{\text{reads}} \cdot T_{\text{QPU}})$ where $T_{\text{embed}}$ can be exponential
\item \textbf{Space}: $O(|\mathcal{V}| \cdot c)$ physical qubits, where $c$ is chain length (typically 2-10)
\item \textbf{Limitations}: Fails when $|\mathcal{V}| > 300$-500 or high connectivity
\end{itemize}

\textbf{Note: add references on new algorithms and scaling boundary of QPU always failing - our problem}

\subsubsection{Method 2: Plot-Based Decomposition}

\paragraph{Description}
Plot-based decomposition partitions the problem by farm, creating one subproblem per farm plus a master problem for unique crop tracking. This ensures constraint preservation since farms are independent. This natural domain-aware partitioning exploits the independence structure inherent in agricultural planning, similar to decomposition strategies used in quantum annealing for scheduling~\cite{venturelli2015quantum} and graph coloring problems~\cite{titiloye2011quantum}.

\paragraph{Mathematical Formulation}

Partition variables into farm-specific subsets plus global U variables:
\begin{equation}
\mathcal{P}_{\text{PlotBased}} = \{\mathcal{P}_1, \mathcal{P}_2, \ldots, \mathcal{P}_{|\mathcal{F}|}, \mathcal{P}_U\}
\end{equation}

where:
\begin{itemize}
\item $\mathcal{P}_i = \{Y_{f_i,c} : c \in \mathcal{C}\}$ for farm $f_i$
\item $\mathcal{P}_U = \{U_c : c \in \mathcal{C}\}$
\end{itemize}

Each farm partition has $|\mathcal{C}|$ variables (one per crop), creating $|\mathcal{F}| + 1$ partitions.

\begin{algorithm}
\caption{Plot-Based Decomposition}
\begin{algorithmic}[1]
\Require Data with $|\mathcal{F}|$ farms, $|\mathcal{C}|$ crops
\Ensure Complete solution $\mathbf{x}$
\State Create partitions: $\mathcal{P}_f = \{Y_{f,c} : c \in \mathcal{C}\}$ for each farm $f$
\State Create U partition: $\mathcal{P}_U = \{U_c : c \in \mathcal{C}\}$
\State $\mathbf{x} \leftarrow \emptyset$
\For{each partition $\mathcal{P}$ in $\{\mathcal{P}_1, \ldots, \mathcal{P}_{|\mathcal{F}|}, \mathcal{P}_U\}$}
    \State Build BQM for variables in $\mathcal{P}$ with objective and local constraints
    \State Embed BQM on QPU: $\phi_{\mathcal{P}} \leftarrow \text{find\_embedding}(\mathcal{P}, G_t)$
    \State Sample: $\mathbf{x}_{\mathcal{P}} \leftarrow \text{QPU.sample}(\text{BQM}_{\mathcal{P}}, \phi_{\mathcal{P}}, n_{\text{reads}})$
    \State Merge with conflict resolution: $\mathbf{x} \leftarrow \text{merge}(\mathbf{x}, \mathbf{x}_{\mathcal{P}})$
\EndFor
\State \Return $\mathbf{x}$
\end{algorithmic}
\end{algorithm}

\paragraph{Conflict Resolution}

When merging partition solutions, farm assignment conflicts are resolved by benefit comparison:

\begin{algorithm}
\caption{Conflict Resolution for Farm Assignments}
\begin{algorithmic}[1]
\Require New assignment $Y_{f,c} = 1$, existing assignments $\mathbf{x}$
\If{$\exists c' : \mathbf{x}[Y_{f,c'}] = 1$} \Comment{Conflict detected}
    \State $b_{\text{new}} \leftarrow b_c \cdot L_f$
    \State $b_{\text{old}} \leftarrow b_{c'} \cdot L_f$
    \If{$b_{\text{new}} > b_{\text{old}}$}
        \State $\mathbf{x}[Y_{f,c'}] \leftarrow 0$ \Comment{Replace with better option}
        \State $\mathbf{x}[Y_{f,c}] \leftarrow 1$
    \EndIf
\Else
    \State $\mathbf{x}[Y_{f,c}] \leftarrow 1$ \Comment{No conflict}
\EndIf
\end{algorithmic}
\end{algorithm}

\paragraph{Complexity}
\begin{itemize}
\item \textbf{Partitions}: $|\mathcal{F}| + 1$
\item \textbf{Partition size}: $|\mathcal{C}|$ variables each
\item \textbf{Total QPU calls}: $|\mathcal{F}| + 1$
\item \textbf{Embedding}: Fast (small partitions)
\item \textbf{Constraint preservation}: Excellent (farms independent)
\end{itemize}

\subsubsection{Method 3: Multilevel Partitioning}

\paragraph{Description}
Multilevel partitioning groups farms into larger clusters of size $k$, reducing the number of partitions at the cost of partition size and potential constraint violations. This hierarchical approach is inspired by multilevel graph partitioning techniques widely used in VLSI design and parallel computing~\cite{karypis1998fast, hendrickson1995multilevel}.

\paragraph{Mathematical Formulation}

Group farms into clusters of size $k$:
\begin{equation}
\mathcal{P}_{\text{Multilevel}} = \{\mathcal{P}_1, \ldots, \mathcal{P}_{\lceil |\mathcal{F}|/k \rceil}, \mathcal{P}_U\}
\end{equation}

where:
\begin{equation}
\mathcal{P}_i = \{Y_{f,c} : f \in \mathcal{F}_i, c \in \mathcal{C}\}
\end{equation}

and $\mathcal{F}_i$ is a subset of $k$ farms. Each partition has $k \cdot |\mathcal{C}|$ variables.

\begin{algorithm}
\caption{Multilevel Partitioning ($k$-farm groups)}
\begin{algorithmic}[1]
\Require Data with $|\mathcal{F}|$ farms, group size $k$
\Ensure Solution $\mathbf{x}$
\State Divide farms into groups: $\mathcal{F} = \bigcup_{i=1}^{\lceil |\mathcal{F}|/k \rceil} \mathcal{F}_i$ where $|\mathcal{F}_i| \leq k$
\For{each farm group $\mathcal{F}_i$}
    \State $\mathcal{P}_i \leftarrow \{Y_{f,c} : f \in \mathcal{F}_i, c \in \mathcal{C}\}$
    \State Build BQM for $\mathcal{P}_i$ with one-crop constraints for each $f \in \mathcal{F}_i$
    \State Solve partition on QPU
    \State Merge solution with conflict resolution
\EndFor
\State Solve U partition
\State \Return $\mathbf{x}$
\end{algorithmic}
\end{algorithm}

\paragraph{Trade-offs}
\begin{itemize}
\item \textbf{Fewer partitions}: $\lceil |\mathcal{F}|/k \rceil + 1$ vs $|\mathcal{F}| + 1$
\item \textbf{Larger partitions}: $k \cdot |\mathcal{C}|$ variables vs $|\mathcal{C}|$
\item \textbf{Embedding difficulty}: Increases with $k$
\item \textbf{Violations}: Can occur when farms in same partition compete for crops
\end{itemize}

\subsubsection{Method 4: Louvain Community Detection}

\paragraph{Description}
Louvain decomposition uses community detection on the variable interaction graph to create partitions that minimize cross-partition edges. This is a graph-theoretic approach that adapts to problem structure. The method is based on the fast community detection algorithm by Blondel et al.~\cite{blondel2008fast}, which maximizes modularity to identify densely connected subgraphs in the variable interaction network.

\paragraph{Mathematical Formulation}

Build interaction graph $G_{\text{int}} = (\mathcal{V}, E_{\text{int}})$ where:
\begin{equation}
E_{\text{int}} = \{(Y_{f,c}, Y_{f,c'}) : f \in \mathcal{F}, c \neq c' \in \mathcal{C}\} \cup \{(Y_{f,c}, U_c) : f \in \mathcal{F}, c \in \mathcal{C}\}
\end{equation}

Apply Louvain algorithm to maximize modularity:
\begin{equation}
Q = \frac{1}{2m} \sum_{i,j} \left[ A_{ij} - \frac{k_i k_j}{2m} \right] \delta(c_i, c_j)
\end{equation}

where $m = |E_{\text{int}}|$, $A$ is adjacency matrix, $k_i$ is degree of node $i$, and $\delta(c_i, c_j) = 1$ if nodes $i,j$ are in same community.

\begin{algorithm}
\caption{Louvain Community Detection Decomposition}
\begin{algorithmic}[1]
\Require Variable interaction graph $G_{\text{int}}$
\Ensure Partition set $\mathcal{P} = \{\mathcal{P}_1, \ldots, \mathcal{P}_n\}$
\State Initialize: each variable in its own community
\Repeat
    \For{each variable $v$}
        \State Find community $C$ that maximizes modularity gain
        \State Move $v$ to $C$ if gain is positive
    \EndFor
    \State Aggregate communities into super-nodes
\Until{no modularity improvement}
\State Split partitions exceeding size limit: $|\mathcal{P}_i| \leq \text{max\_size}$
\State \Return $\mathcal{P}$
\end{algorithmic}
\end{algorithm}

\paragraph{Characteristics}
\begin{itemize}
\item \textbf{Adaptive}: Partition structure follows problem connectivity
\item \textbf{Many partitions}: Typically creates $|\mathcal{F}|$ to $2|\mathcal{F}|$ partitions
\item \textbf{Variable partition sizes}: From 2 to max\_size variables
\item \textbf{Modularity optimization}: Minimizes cross-partition interactions
\end{itemize}

\subsubsection{Method 5: CQM-First Decomposition}

\paragraph{Description}
CQM-first decomposition partitions at the CQM level before converting to BQM, preserving constraint structure within partitions. This addresses the fundamental issue that BQM-first approaches lose constraint information during penalty encoding~\cite{lucas2014ising}. By maintaining explicit constraints within subproblems, this method improves solution quality compared to standard penalty-based approaches.

\paragraph{Key Innovation}

Standard decomposition: $\text{CQM} \rightarrow \text{BQM} \rightarrow \text{Partition}$

CQM-first: $\text{CQM} \rightarrow \text{Partition} \rightarrow \text{Sub-CQMs} \rightarrow \text{BQMs}$

\begin{algorithm}
\caption{CQM-First Decomposition with Constraint Preservation}
\begin{algorithmic}[1]
\Require CQM with variables $\mathcal{V}$, constraints $\mathcal{C}$
\Require Partition function $\Pi: \mathcal{V} \rightarrow \{\mathcal{P}_1, \ldots, \mathcal{P}_n\}$
\Ensure Solution $\mathbf{x}$
\State Partition variables: $\{\mathcal{P}_1, \ldots, \mathcal{P}_n\} \leftarrow \Pi(\mathcal{V})$
\State Identify master partition $\mathcal{P}_U$ containing U variables
\State \textbf{Phase 1: Solve Master}
\State Extract sub-CQM for $\mathcal{P}_U$ with food group constraints
\State Convert to BQM: $\text{BQM}_U \leftarrow \text{cqm\_to\_bqm}(\text{Sub-CQM}_U, \lambda)$
\State $\mathbf{x}_U \leftarrow \text{QPU.sample}(\text{BQM}_U)$
\State \textbf{Phase 2: Solve Subproblems with Fixed U}
\For{partition $\mathcal{P}_i$ where $i \neq U$}
    \State Extract sub-CQM for $\mathcal{P}_i$ with $\mathbf{x}_U$ fixed
    \State Convert to BQM: $\text{BQM}_i \leftarrow \text{cqm\_to\_bqm}(\text{Sub-CQM}_i, \lambda)$
    \State $\mathbf{x}_i \leftarrow \text{QPU.sample}(\text{BQM}_i)$
    \State Merge with conflict resolution: $\mathbf{x} \leftarrow \text{merge}(\mathbf{x}, \mathbf{x}_i)$
\EndFor
\State \Return $\mathbf{x}$
\end{algorithmic}
\end{algorithm}

\paragraph{Constraint Extraction}

The sub-CQM extraction process preserves constraints:

\begin{algorithm}
\caption{Extract Sub-CQM}
\begin{algorithmic}[1]
\Require CQM, partition variables $\mathcal{P}$, fixed variables $\mathcal{F}_{\text{vars}}$
\Ensure Sub-CQM containing only $\mathcal{P}$ variables
\State Create new CQM: $\text{Sub-CQM} \leftarrow \emptyset$
\For{constraint $c \in \text{CQM.constraints}$}
    \State $\mathcal{V}_c \leftarrow$ variables in constraint $c$
    \State $\mathcal{V}_{\text{partition}} \leftarrow \mathcal{V}_c \cap \mathcal{P}$
    \State $\mathcal{V}_{\text{fixed}} \leftarrow \mathcal{V}_c \cap \mathcal{F}_{\text{vars}}$
    \If{$\mathcal{V}_{\text{partition}} \neq \emptyset$}
        \State Substitute fixed values into constraint
        \State Add simplified constraint to Sub-CQM
    \EndIf
\EndFor
\State \Return Sub-CQM
\end{algorithmic}
\end{algorithm}

\paragraph{Advantages}
\begin{itemize}
\item \textbf{Constraint preservation}: Constraints remain explicit within partitions
\item \textbf{Better penalty encoding}: Lagrange multipliers applied per partition
\item \textbf{Two-phase coordination}: Master-subproblem structure ensures global feasibility
\end{itemize}

\subsubsection{Method 6: Coordinated Master-Subproblem}

\paragraph{Description}
Coordinated decomposition uses a rigorous two-level optimization where the master problem selects which crops to use (U variables) and farm subproblems independently assign these crops to farms. This hierarchical structure is inspired by classical decomposition techniques such as Benders decomposition~\cite{geoffrion1972generalized} and the master-subproblem framework for large-scale optimization~\cite{lasdon1970optimization}.

\paragraph{Mathematical Formulation}

\textbf{Master Problem:}
\begin{align}
\text{minimize} \quad & \sum_{c \in \mathcal{C}} \lambda_c \cdot U_c \label{eq:master_obj}\\
\text{subject to} \quad & \sum_{c \in G_g} U_c \geq m_g, \quad \forall g \in \mathcal{G} \label{eq:master_fg}\\
& U_c \in \{0,1\}, \quad \forall c \in \mathcal{C}
\end{align}

The master objective uses small penalties $\lambda_c$ to encourage crop selection while satisfying food group diversity.

\textbf{Farm Subproblems (for each farm $f$):}
\begin{align}
\text{maximize} \quad & \sum_{c \in \mathcal{C}} b_c \cdot L_f \cdot Y_{f,c} \label{eq:sub_obj}\\
\text{subject to} \quad & \sum_{c \in \mathcal{C}} Y_{f,c} \leq 1 \label{eq:sub_one_crop}\\
& Y_{f,c} \leq U_c^*, \quad \forall c \in \mathcal{C} \label{eq:sub_u_fixed}\\
& Y_{f,c} \in \{0,1\}, \quad \forall c \in \mathcal{C}
\end{align}

where $U_c^*$ is the fixed value from the master solution.

\begin{algorithm}
\caption{Coordinated Master-Subproblem Decomposition}
\begin{algorithmic}[1]
\Require Data with farms $\mathcal{F}$, crops $\mathcal{C}$, food groups $\mathcal{G}$
\Ensure Solution $\mathbf{x} = (\mathbf{Y}, \mathbf{U})$
\State \textbf{Step 1: Solve Master Problem}
\State Build master BQM for U variables with food group constraints
\State $\mathbf{U}^* \leftarrow \text{QPU.sample}(\text{BQM}_{\text{master}})$
\State $\text{selected\_crops} \leftarrow \{c : U_c^* = 1\}$
\State \textbf{Step 2: Solve Farm Subproblems}
\For{each farm $f \in \mathcal{F}$}
    \State Build farm BQM with objective $\max \sum_{c \in \text{selected\_crops}} b_c \cdot L_f \cdot Y_{f,c}$
    \State Add one-crop constraint: $\sum_{c} Y_{f,c} \leq 1$
    \State Add U-linking: $Y_{f,c} \leq U_c^*$ encoded as penalty
    \State $\mathbf{Y}_f^* \leftarrow \text{QPU.sample}(\text{BQM}_f)$
    \State $\mathbf{Y}[f, :] \leftarrow \mathbf{Y}_f^*$
\EndFor
\State \Return $\mathbf{x} = (\mathbf{Y}, \mathbf{U}^*)$
\end{algorithmic}
\end{algorithm}

\paragraph{Properties}
\begin{itemize}
\item \textbf{Hierarchical}: Clear master-subproblem structure
\item \textbf{Independent subproblems}: Farms solved in parallel
\item \textbf{Global constraint enforcement}: Master ensures food group diversity
\item \textbf{QPU calls}: $1 + |\mathcal{F}|$ (one master + one per farm)
\end{itemize}

\subsubsection{Method 7: Spectral Clustering}

\paragraph{Description}
Spectral clustering uses the eigenvectors of the graph Laplacian to partition variables, grouping tightly connected components while cutting weak connections. This method leverages the spectral properties of graphs~\cite{vonluxburg2007tutorial, ng2001spectral} and uses normalized cuts~\cite{shi2000normalized} to achieve balanced partitions suitable for quantum hardware constraints.

\paragraph{Mathematical Formulation}

Given interaction graph $G = (\mathcal{V}, E)$, compute:

\textbf{Adjacency matrix:} $A_{ij} = \begin{cases} 1 & \text{if } (i,j) \in E \\ 0 & \text{otherwise} \end{cases}$

\textbf{Degree matrix:} $D_{ii} = \sum_j A_{ij}$

\textbf{Normalized Laplacian:} $\mathcal{L} = I - D^{-1/2} A D^{-1/2}$

\textbf{Spectral embedding:} Compute eigenvectors $\mathbf{v}_1, \ldots, \mathbf{v}_k$ corresponding to smallest eigenvalues

\textbf{Clustering:} Apply k-means on the embedding matrix $V = [\mathbf{v}_1 | \cdots | \mathbf{v}_k]$

\begin{algorithm}
\caption{Spectral Clustering Decomposition}
\begin{algorithmic}[1]
\Require Interaction graph $G = (\mathcal{V}, E)$, number of clusters $k$
\Ensure Partition set $\mathcal{P} = \{\mathcal{P}_1, \ldots, \mathcal{P}_k\}$
\State Construct adjacency matrix $A$ from $G$
\State Compute degree matrix $D$
\State Compute normalized Laplacian: $\mathcal{L} = I - D^{-1/2} A D^{-1/2}$
\State Compute $k$ smallest eigenvectors: $V = [\mathbf{v}_1, \ldots, \mathbf{v}_k]$
\State Apply k-means clustering on rows of $V$ to get cluster assignments
\For{cluster $i = 1$ to $k$}
    \State $\mathcal{P}_i \leftarrow$ variables assigned to cluster $i$
\EndFor
\State \Return $\mathcal{P}$
\end{algorithmic}
\end{algorithm}

\paragraph{Characteristics}
\begin{itemize}
\item \textbf{Spectral properties}: Uses graph spectrum for optimal cuts
\item \textbf{Balanced partitions}: k-means encourages similar partition sizes
\item \textbf{Computationally expensive}: Eigenvalue decomposition $O(|\mathcal{V}|^3)$
\item \textbf{Fixed partition count}: User specifies $k$
\end{itemize}

\subsubsection{Method 8: HybridGrid Decomposition}

\paragraph{Description}
HybridGrid partitioning creates a 2D grid structure by dividing both farms \emph{and} crops simultaneously. This produces many small partitions that are easy to embed while maintaining local constraint coherence. The approach is inspired by domain decomposition methods used in parallel computing and numerical PDEs~\cite{toselli2005domain, smith1996domain}, adapted specifically for the bipartite structure of farm-crop assignment problems.

\paragraph{Mathematical Formulation}

Given group sizes $k_F$ for farms and $k_C$ for crops, create a grid of partitions:

\begin{equation}
\mathcal{P}_{\text{HybridGrid}} = \{\mathcal{P}_{(i,j)} : i \in [1, \lceil |\mathcal{F}|/k_F \rceil], j \in [1, \lceil |\mathcal{C}|/k_C \rceil]\} \cup \{\mathcal{P}_U\}
\end{equation}

where each grid cell contains:
\begin{equation}
\mathcal{P}_{(i,j)} = \{Y_{f,c} : f \in \mathcal{F}_{[k_F(i-1)+1:k_F \cdot i]}, c \in \mathcal{C}_{[k_C(j-1)+1:k_C \cdot j]}\}
\end{equation}

For example, with $k_F = 5$ farms and $k_C = 9$ crops:
\begin{itemize}
\item Partition size: $5 \times 9 = 45$ variables (very easy to embed)
\item For 100 farms: $20 \times 3 = 60$ grid partitions + 1 U partition
\item For 1000 farms: $200 \times 3 = 600$ grid partitions + 1 U partition
\end{itemize}

\begin{algorithm}
\caption{HybridGrid Decomposition}
\begin{algorithmic}[1]
\Require Farm group size $k_F$, crop group size $k_C$
\Ensure Partition set $\mathcal{P}$
\State $\mathcal{P} \leftarrow \emptyset$
\For{$i = 0$ to $\lfloor |\mathcal{F}|/k_F \rfloor$}
    \State $\mathcal{F}_i \leftarrow \{f_{k_F \cdot i + 1}, \ldots, f_{\min(k_F(i+1), |\mathcal{F}|)}\}$
    \For{$j = 0$ to $\lfloor |\mathcal{C}|/k_C \rfloor$}
        \State $\mathcal{C}_j \leftarrow \{c_{k_C \cdot j + 1}, \ldots, c_{\min(k_C(j+1), |\mathcal{C}|)}\}$
        \State $\mathcal{P} \leftarrow \mathcal{P} \cup \{\{Y_{f,c} : f \in \mathcal{F}_i, c \in \mathcal{C}_j\}\}$
    \EndFor
\EndFor
\State $\mathcal{P}_U \leftarrow \{U_c : c \in \mathcal{C}\}$
\State \Return $\mathcal{P} \cup \{\mathcal{P}_U\}$
\end{algorithmic}
\end{algorithm}

\paragraph{Key Advantages}

\begin{enumerate}
\item \textbf{Small partition size}: $k_F \times k_C$ variables (typically 27-65) ensures easy embedding
\item \textbf{No embedding failures}: Partitions fit easily on QPU Pegasus topology
\item \textbf{Consistent performance}: Predictable partition sizes across all problem scales
\item \textbf{Constraint locality}: Each partition covers a coherent subset of the problem
\item \textbf{Linear scaling}: Number of partitions scales as $O(|\mathcal{F}| / k_F)$
\end{enumerate}

\subsubsection{Comparison of Methods}

\begin{table}[h]
\centering
\caption{Decomposition Method Comparison}
\label{tab:method_comparison}
\scriptsize
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Partition Size} & \textbf{\# Partitions} & \textbf{Constraint} & \textbf{Coordination} & \textbf{Scalability} \\
\midrule
Direct QPU & All & 1 & Penalty & N/A & Poor \\
PlotBased & 27 & $|\mathcal{F}|+1$ & Partial & Low & Excellent \\
Multilevel(5) & 135 & $|\mathcal{F}|/5+1$ & Partial & Medium & Good \\
Multilevel(10) & 270 & $|\mathcal{F}|/10+1$ & Partial & Medium & Good \\
Louvain & Adaptive & Variable & Partial & Medium & Good \\
Spectral & Balanced & $k$ & Partial & Medium & Good \\
CQM-First & 27 & $|\mathcal{F}|+1$ & Strong & High & Excellent \\
Coordinated & 27 & $|\mathcal{F}|+1$ & Strong & High & Excellent \\
HybridGrid & $45$ & $O(|\mathcal{F}|/k_F)$ & Partial & Low & Excellent \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Note on Quantum Annealing Decomposition}
The challenge of embedding large optimization problems onto quantum annealers with limited qubit connectivity has motivated extensive research into partitioning strategies~\cite{booth2017partitioning, bian2020solving, date2019efficiently}. The methods presented here represent adaptations of classical decomposition techniques to the unique constraints and opportunities of quantum hardware.



\subsection{Data and Preprocessing}

Our study uses agricultural data from Bangladesh and Indonesia, provided by the Global Alliance for Improved Nutrition (GAIN). This dataset encompasses 27 food crops across 5 food groups, with normalized scores for nutritional value, nutrient density, environmental impact, affordability, and sustainability. The food groups include animal-source foods (beef, chicken, egg, lamb, pork), fruits (apple, avocado, banana, durian, guava, mango, orange, papaya, watermelon), pulses, nuts and seeds (chickpeas, peanuts, tempeh, tofu), starchy staples (corn, potato), and vegetables (cabbage, cucumber, eggplant, long bean, pumpkin, spinach, tomatoes).

\subsubsection{Crop Family Aggregation}

To manage problem complexity while preserving agronomic diversity, we aggregate the 27 individual food crops into 6 crop families in Study III (Formulation B). This aggregation is implemented directly within the rotation scenario loader rather than as a separate preprocessing function, reducing the number of variables by a factor of 4.5 (from $F \times 27 \times 3$ to $F \times 6 \times 3$) while maintaining meaningful distinctions between crop types from a rotation planning perspective. The aggregation maps Legumes to include beans, lentils, chickpeas, peas, and soybeans; Grains to encompass rice, wheat, maize, barley, and oats; Vegetables to cover tomatoes, cabbage, peppers, spinach, and broccoli; Root Vegetables to include potatoes, carrots, cassava, sweet potatoes, and beets; Fruits to contain bananas, oranges, mangoes, apples, and grapes; and Proteins/Other to capture nuts, seeds, herbs, and spices.

This aggregation scheme is agronomically meaningful because rotation synergies typically operate at the family level. For example, all legumes fix nitrogen regardless of species, and all brassicas (a vegetable subfamily) are susceptible to similar pests. The benefit score for each family is computed as the weighted average of its constituent crops' scores, preserving the relative ranking of food value categories.

\subsubsection{Farm Size Distribution and Spatial Layout}
The farm areas $L_f$ are sampled from a realistic size distribution based on global agricultural survey data. In the Global South, farm sizes follow a highly skewed distribution: approximately 84\% of farms are smaller than 2 hectares, operating only 12\% of total agricultural land \cite{lowder2016number, lowder2021farms}. Among these, farms smaller than 1 hectare constitute about 72\% of all holdings \cite{fao2014farms}. In contrast, farms larger than 20 hectares represent less than 10\% of holdings but occupy the majority of agricultural land, with the largest 1\% of farms controlling over 70\% of global farmland \cite{lowder2021farms}. Our sampling procedure captures this heterogeneity, ensuring that problem instances reflect the diversity of real-world farming landscapes observed in regions such as Sub-Saharan Africa, South Asia, and Latin America \cite{samberg2016subnational}.

Farms are assigned spatial coordinates on a 2D grid, and the neighbor graph is constructed by connecting each farm to its 4 nearest neighbors using Euclidean distance. This spatial structure is essential for modeling realistic agricultural interactions such as pest dispersal \cite{garzon2022methodological}, pollination services \cite{ponisio2015spatial, rahimi2021estimating}, and shared infrastructure. The k-nearest neighbor graph construction approach is widely used in spatial agricultural modeling \cite{zhang2024efficient, finley2006forest} and captures essential properties of agricultural landscapes, including local clustering and limited long-range connections \cite{cranmer2012landscape}. The resulting neighbor graph has topological properties similar to real agricultural landscapes, where spatial proximity determines ecological interactions and resource sharing patterns \cite{moreira2018plant, chacon2015landscape}.

\subsection{Mapping to D-Wave QPU: Decomposition Strategies for Study III}

Direct embedding of large-scale optimization problems on current quantum annealing hardware faces significant challenges. The D-Wave Advantage system features over 5,600 qubits arranged in a Pegasus topology~\cite{dwave2020advantage, dwave2022pegasus}, where each qubit connects to approximately 15 neighbors. This represents a substantial improvement over the previous Chimera topology (6 connections per qubit)~\cite{boothler2022benchmarking}, but remains far from the all-to-all connectivity required by many optimization problems. Problems requiring dense connectivity between logical variables must use chains of physical qubits, which consumes the qubit budget rapidly and introduces chain break errors~\cite{date2019efficiently}. For our 100-farm instances with 1,800 variables, direct embedding is infeasible given current hardware constraints.

To overcome this limitation, we developed hierarchical decomposition strategies that partition the global problem into subproblems small enough to embed efficiently on the QPU while maintaining solution quality through iterative coordination. Our approach is motivated by recent advances in quantum annealing decomposition~\cite{li2025efficient, booth2017partitioning, bass2021optimizing}, which demonstrate that problem-specific partitioning strategies can significantly improve solution quality compared to generic decomposition methods. The challenge of embedding large optimization problems onto quantum annealers with limited qubit connectivity has motivated extensive research into partitioning strategies~\cite{bian2020solving, yarkoni2022quantum, okada2020breaking}. Our key insight is that subproblems of 18 or fewer variables can be embedded as native cliques on the Pegasus topology, requiring no chains and thus eliminating embedding overhead entirely~\cite{dwave2022pegasus}.

\subsubsection{Strategy 1: Clique Decomposition (Farm-by-Farm)}

The clique decomposition strategy treats each farm as an independent subproblem, solving the crop allocation for that farm across all three time periods. This domain-aware partitioning exploits the natural independence structure of the agricultural planning problem, similar to decomposition strategies used in quantum annealing for scheduling~\cite{venturelli2015quantum} and graph coloring problems~\cite{titiloye2011quantum}. Each subproblem has $C \times T = 6 \times 3 = 18$ binary variables, which fits perfectly within a native clique on the Pegasus topology.

\paragraph{Mathematical Formulation}

For each farm $f \in \mathcal{F}$, we construct a farm-specific optimization problem over variables $\{Y_{f,c,t}\}_{c \in \mathcal{C}, t \in \mathcal{T}}$ where $\mathcal{C}$ represents the 6 crop families and $\mathcal{T} = \{1,2,3\}$ represents the three time periods. The farm subproblem objective incorporates three components:

\begin{align}
\mathcal{O}_f = & \sum_{c \in \mathcal{C}} \sum_{t \in \mathcal{T}} \frac{B_c \cdot A_f}{A_{\text{total}}} \cdot Y_{f,c,t} \label{eq:farm_benefit} \\
& + \sum_{t=2}^{T} \sum_{c_1, c_2 \in \mathcal{C}} \frac{\gamma_{\text{rot}} \cdot R_{c_1, c_2} \cdot A_f}{A_{\text{total}}} \cdot Y_{f,c_1,t-1} \cdot Y_{f,c_2,t} \label{eq:farm_rotation} \\
& + \sum_{f' \in \mathcal{N}(f)} \sum_{t \in \mathcal{T}} \sum_{c_1, c_2 \in \mathcal{C}} \frac{\gamma_{\text{spat}} \cdot S_{c_1,c_2}}{A_{\text{total}}} \cdot Y_{f,c_1,t} \cdot Y_{f',c_2,t}^{(k-1)} \label{eq:farm_spatial}
\end{align}

where $Y_{f',c_2,t}^{(k-1)}$ denotes the assignment for neighboring farm $f'$ from the previous iteration $k-1$. The Binary Quadratic Model (BQM) is constructed by converting the objective to minimization form and adding penalty terms for the one-crop-per-period constraint~\cite{lucas2014ising}:

\begin{equation}
E_f(Y) = -\mathcal{O}_f + \lambda_{\text{penalty}} \sum_{t \in \mathcal{T}} \left(\sum_{c \in \mathcal{C}} Y_{f,c,t} - 1\right)^2
\end{equation}

For each farm $f$, we construct a Binary Quadratic Model (BQM) over the variables $\{Y_{f,c,t}\}_{c \in \mathcal{C}, t \in \mathcal{T}}$. The linear terms encode the crop benefits (negated for minimization), the quadratic terms encode the rotation synergies between consecutive periods, and additional quadratic terms implement the one-hot penalty for each period~\cite{lucas2014ising}. The BQM is then submitted to the DWaveCliqueSampler, which automatically finds a native clique embedding and returns 100 samples per subproblem.

\paragraph{Iterative Boundary Refinement}

Because the spatial interaction terms couple different farms, a single pass through the decomposition ignores neighbor effects. To address this, we employ iterative refinement over 3 boundary iterations, a technique inspired by domain decomposition methods in parallel computing~\cite{toselli2005domain}. In each iteration after the first, we add small bias terms to each farm's BQM based on the solutions found for neighboring farms in the previous iteration. 

The bias terms are computed as:
\begin{equation}
b_{f,c,t}^{(k)} = \sum_{f' \in \mathcal{N}(f)} \sum_{c' \in \mathcal{C}} \gamma_{\text{spat}} \cdot S_{c,c'} \cdot Y_{f',c',t}^{(k-1)}
\end{equation}

These biases approximate the spatial coupling terms, encouraging compatible crop choices across farm boundaries. Empirically, 3 iterations are sufficient for convergence, reducing the optimality gap from 20--25\% (single iteration) to 11--15\% (three iterations).

\begin{algorithm}
\caption{Clique Decomposition with Iterative Refinement}
\begin{algorithmic}[1]
\Require Farms $\mathcal{F}$, crops $\mathcal{C}$, periods $\mathcal{T} = \{1,2,3\}$
\Require Neighbor graph $\mathcal{N}(f)$ for each farm $f$
\Ensure Solution $\mathbf{Y} = \{Y_{f,c,t}\}$
\State Initialize: $Y_{f,c,t}^{(0)} \leftarrow 0$ for all $f, c, t$
\For{iteration $k = 1$ to $K_{\text{max}}$ (typically 3)}
    \For{each farm $f \in \mathcal{F}$}
        \State Compute neighbor biases: $b_{f,c,t}^{(k)} \leftarrow \sum_{f' \in \mathcal{N}(f)} \sum_{c'} \gamma_{\text{spat}} \cdot S_{c,c'} \cdot Y_{f',c',t}^{(k-1)}$
        \State Build BQM: $E_f = -\mathcal{O}_f + \lambda \sum_t (\sum_c Y_{f,c,t} - 1)^2 - \sum_{c,t} b_{f,c,t}^{(k)} \cdot Y_{f,c,t}$
        \State Embed BQM on QPU: $\phi_f \leftarrow \text{DWaveCliqueSampler.find\_embedding}(E_f)$
        \State Sample: $\mathbf{Y}_f^{(k)} \leftarrow \text{QPU.sample}(E_f, \phi_f, n_{\text{reads}} = 100)$
        \State Update: $Y_{f,c,t}^{(k)} \leftarrow \mathbf{Y}_f^{(k)}[c,t]$ (best sample)
    \EndFor
    \State Evaluate global objective $\mathcal{O}_{\text{global}}(\mathbf{Y}^{(k)})$
    \If{convergence criterion met}
        \State \textbf{break}
    \EndIf
\EndFor
\State \Return $\mathbf{Y}^{(K_{\text{max}})}$ (best across all iterations)
\end{algorithmic}
\end{algorithm}

The algorithm proceeds as follows: we initialize all solutions to an empty assignment, then for each iteration from 1 to 3, we loop over all farms, building the BQM with neighbor biases from the previous iteration, sampling from the QPU, and updating the solution for that farm. After each iteration, we evaluate the global objective and retain the best solution found. This approach is highly parallelizable; in principle, all farm subproblems within an iteration could be solved simultaneously on separate QPU calls, similar to parallel quantum annealing strategies~\cite{pelofske2021parallel}.

\paragraph{Complexity Analysis}
\begin{itemize}
\item \textbf{Subproblem size}: 18 variables per farm (fits native Pegasus cliques)
\item \textbf{QPU calls}: $K_{\text{max}} \times |\mathcal{F}|$ (typically $3 \times F$)
\item \textbf{Embedding time}: Near-zero (native clique, no chains)
\item \textbf{Chain breaks}: $<$1\% (minimal chaining required)
\item \textbf{Convergence}: 3 iterations sufficient empirically
\item \textbf{Parallelization potential}: $O(1)$ time with $|\mathcal{F}|$ QPUs
\end{itemize}

\subsubsection{Strategy 2: Spatial-Temporal Decomposition}

The spatial-temporal decomposition strategy takes a different approach, partitioning the problem along both spatial and temporal dimensions simultaneously. This multi-dimensional decomposition is motivated by the observation that both spatial clustering and temporal decoupling can reduce problem complexity while preserving essential structure~\cite{ushijima2017graph}. Farms are grouped into spatial clusters of 2 to 5 neighboring farms using a simple nearest-neighbor heuristic, preserving local spatial interactions within each cluster. Within each cluster, we further slice by time period, solving one period at a time.

\paragraph{Mathematical Formulation}

Given a spatial clustering $\mathcal{F} = \bigcup_{i=1}^{N_c} \mathcal{F}_i$ where each cluster $\mathcal{F}_i$ contains $k_i \leq 5$ neighboring farms, we create cluster-period subproblems:

\begin{equation}
\mathcal{P}_{i,t} = \{Y_{f,c,t} : f \in \mathcal{F}_i, c \in \mathcal{C}\}
\end{equation}

Each subproblem optimizes crop allocation for cluster $i$ in period $t$, with constraints:
\begin{align}
\text{maximize} \quad & \sum_{f \in \mathcal{F}_i} \sum_{c \in \mathcal{C}} \frac{B_c \cdot A_f}{A_{\text{total}}} \cdot Y_{f,c,t} \\
& + \sum_{(f_1,f_2) \in \mathcal{E}_i} \sum_{c_1,c_2 \in \mathcal{C}} \frac{\gamma_{\text{spat}} \cdot S_{c_1,c_2}}{A_{\text{total}}} \cdot Y_{f_1,c_1,t} \cdot Y_{f_2,c_2,t} \label{eq:intra_cluster_spatial}
\end{align}

where $\mathcal{E}_i$ is the set of edges within cluster $i$. For period $t > 1$, rotation effects are incorporated by fixing previous period assignments:

\begin{equation}
\text{Rotation term:} \quad \sum_{f \in \mathcal{F}_i} \sum_{c_1,c_2 \in \mathcal{C}} \frac{\gamma_{\text{rot}} \cdot R_{c_1,c_2} \cdot A_f}{A_{\text{total}}} \cdot Y_{f,c_1,t-1}^* \cdot Y_{f,c_2,t}
\end{equation}

where $Y_{f,c_1,t-1}^*$ are fixed assignments from the previous temporal slice.

This results in subproblems with at most $3 \text{ farms} \times 6 \text{ crops} \times 1 \text{ period} = 18$ variables, again fitting within native cliques. The temporal slicing allows rotation synergies within clusters to be handled through sequential solving: when solving period $t$, the solutions from period $t-1$ are fixed, providing a boundary condition that captures the rotation effects. This sequential approach is analogous to time-stepping methods in numerical simulation, where future states are computed based on fixed past states.

\begin{algorithm}
\caption{Spatial-Temporal Decomposition}
\begin{algorithmic}[1]
\Require Farms $\mathcal{F}$, spatial clustering $\{\mathcal{F}_1, \ldots, \mathcal{F}_{N_c}\}$
\Require Crops $\mathcal{C}$, periods $\mathcal{T} = \{1,2,3\}$
\Ensure Solution $\mathbf{Y}$
\State Initialize: $\mathbf{Y} \leftarrow \emptyset$
\For{period $t = 1$ to $T$}
    \For{each cluster $\mathcal{F}_i$}
        \State Build cluster-period BQM for variables $\{Y_{f,c,t} : f \in \mathcal{F}_i, c \in \mathcal{C}\}$
        \State Include intra-cluster spatial terms (Equation~\ref{eq:intra_cluster_spatial})
        \If{$t > 1$}
            \State Add rotation terms with fixed $Y_{f,c,t-1}^*$ from previous period
        \EndIf
        \State Add inter-cluster boundary biases from neighboring clusters
        \State Embed and solve on QPU: $\mathbf{Y}_i^{(t)} \leftarrow \text{QPU.sample}(\text{BQM}_{i,t})$
        \State Update: $\mathbf{Y}[f,c,t] \leftarrow \mathbf{Y}_i^{(t)}[f,c]$ for all $f \in \mathcal{F}_i$
    \EndFor
    \State Perform boundary refinement iteration across clusters
\EndFor
\State \Return $\mathbf{Y}$
\end{algorithmic}
\end{algorithm}

Boundary coordination is required both between spatial clusters (to handle inter-cluster spatial interactions) and between time periods (already handled by sequential solving). The iterative refinement process is similar to clique decomposition but operates over cluster-period pairs rather than individual farms.

This strategy is particularly effective when spatial interactions are strong, as it explicitly preserves neighbor relationships within clusters rather than approximating them through bias terms alone.

\paragraph{Clustering Strategy}

Spatial clusters are formed using a greedy nearest-neighbor algorithm:
\begin{enumerate}
    \item Sort farms by spatial coordinates
    \item Initialize first cluster with first farm
    \item For each remaining farm $f$:
        \begin{itemize}
            \item Find cluster $\mathcal{F}_i$ with nearest centroid
            \item If $|\mathcal{F}_i| < k_{\max}$ (typically 5), add $f$ to $\mathcal{F}_i$
            \item Otherwise, create new cluster with $f$
        \end{itemize}
\end{enumerate}

This produces spatially coherent clusters with bounded size, ensuring subproblems remain embeddable.

\paragraph{Complexity Analysis}
\begin{itemize}
\item \textbf{Subproblem size}: $\leq 18$ variables per cluster-period
\item \textbf{Number of clusters}: $\lceil |\mathcal{F}| / k_{\max} \rceil$ (typically $\lceil F/5 \rceil$)
\item \textbf{QPU calls}: $T \times N_c = 3 \times \lceil F/5 \rceil$
\item \textbf{Advantage}: Preserves spatial structure within clusters
\item \textbf{Disadvantage}: Requires sequential temporal solving (no time parallelization)
\end{itemize}

\subsubsection{Strategy 3: Hierarchical Multi-Level Approach}

For the largest problem instances (50 to 100 farms), we employ a three-level hierarchical approach that combines aggregation with spatial decomposition. This method draws inspiration from multilevel graph partitioning techniques~\cite{karypis1998fast, hendrickson1995multilevel} and recent work on hierarchical quantum optimization~\cite{zeng2025hierarchical}. At the first level, crops are aggregated from 27 foods to 6 families, reducing the variable count by 4.5$\times$. At the second level, farms are partitioned into spatial clusters of approximately 5 farms each, based on k-means clustering of farm coordinates. At the third level, each cluster is solved on the QPU as a single subproblem with $5 \times 6 \times 3 = 90$ variables.

\paragraph{Three-Level Hierarchy}

\textbf{Level 1 (Crop Aggregation):} Map 27 individual crops to 6 crop families:
\begin{equation}
\mathcal{C}_{\text{fine}} \rightarrow \mathcal{C}_{\text{coarse}}, \quad |\mathcal{C}_{\text{coarse}}| = 6
\end{equation}

Aggregation preserves food group structure and nutritional characteristics through weighted averaging of benefit scores.

\textbf{Level 2 (Spatial Clustering):} Partition farms into $N_c = \lceil |\mathcal{F}| / 5 \rceil$ clusters using k-means on $(x_f, y_f)$ coordinates:
\begin{equation}
\mathcal{F} = \bigcup_{i=1}^{N_c} \mathcal{F}_i, \quad |\mathcal{F}_i| \approx 5
\end{equation}

\textbf{Level 3 (Cluster Optimization):} Each cluster subproblem contains:
\begin{equation}
|\mathcal{P}_i| = |\mathcal{F}_i| \times |\mathcal{C}_{\text{coarse}}| \times T \approx 5 \times 6 \times 3 = 90 \text{ variables}
\end{equation}

\begin{algorithm}
\caption{Hierarchical Multi-Level Decomposition}
\begin{algorithmic}[1]
\Require Farms $\mathcal{F}$, fine crops $\mathcal{C}_{\text{fine}}$ (27), periods $\mathcal{T}$
\Ensure Solution $\mathbf{Y}$
\State \textbf{Level 1: Crop Aggregation}
\State $\mathcal{C}_{\text{coarse}} \leftarrow \text{aggregate\_crops}(\mathcal{C}_{\text{fine}})$ \Comment{27 $\to$ 6 families}
\State Compute aggregated benefits: $B_g \leftarrow \text{weighted\_avg}(\{B_c : c \in \text{family } g\})$
\State \textbf{Level 2: Spatial Clustering}
\State $\{\mathcal{F}_1, \ldots, \mathcal{F}_{N_c}\} \leftarrow \text{k\_means\_cluster}(\mathcal{F}, k=5)$
\State \textbf{Level 3: Cluster Solving with Coordination}
\For{iteration $k = 1$ to $K_{\text{coord}}$ (typically 3)}
    \For{each cluster $i = 1$ to $N_c$}
        \State Build cluster BQM with 90 variables: $\{Y_{f,c,t} : f \in \mathcal{F}_i, c \in \mathcal{C}_{\text{coarse}}, t \in \mathcal{T}\}$
        \State Add temporal rotation terms (within cluster)
        \State Add spatial terms (intra-cluster and boundary biases)
        \State Embed BQM: $\phi_i \leftarrow \text{MinorMiner}(\text{BQM}_i, G_{\text{Pegasus}})$
        \State Sample: $\mathbf{Y}_i^{(k)} \leftarrow \text{QPU.sample}(\text{BQM}_i, \phi_i, n_{\text{reads}}=100)$
        \State Update global solution: $\mathbf{Y}^{(k)} \leftarrow \text{merge}(\mathbf{Y}^{(k)}, \mathbf{Y}_i^{(k)})$
    \EndFor
\EndFor
\State \textbf{Optional: Disaggregation}
\State $\mathbf{Y}_{\text{fine}} \leftarrow \text{disaggregate}(\mathbf{Y}, \mathcal{C}_{\text{coarse}} \rightarrow \mathcal{C}_{\text{fine}})$
\State \Return $\mathbf{Y}$ or $\mathbf{Y}_{\text{fine}}$
\end{algorithmic}
\end{algorithm}

Subproblems of 90 variables require embedding rather than native clique solving, introducing some overhead. However, the DWaveCliqueSampler can still find efficient embeddings for problems of this size on the Pegasus topology~\cite{boothler2022benchmarking}, and the reduced number of subproblems (20 clusters for 100 farms) reduces the total number of QPU calls. The improved connectivity of Pegasus compared to Chimera topology results in shorter chain lengths, which correlates with better solution quality and faster convergence~\cite{dwave2020advantage}. Boundary coordination between clusters follows the same iterative refinement approach, with 3 iterations typically sufficient for convergence.

\paragraph{Embedding Considerations}

Unlike the previous strategies that fit within native cliques, 90-variable subproblems require chain-based embedding:
\begin{itemize}
    \item \textbf{Expected chain length}: 2--4 physical qubits per logical variable
    \item \textbf{Embedding time}: 5--30 seconds per cluster (varies with connectivity)
    \item \textbf{Chain break rate}: $<$3\% with auto-scaled chain strength
    \item \textbf{Mitigation}: Post-processing with majority vote on chain qubits
\end{itemize}

This hierarchical approach scales well to problem sizes beyond our current test range, as the cluster size and aggregation level can be adjusted to balance subproblem size against coordination overhead. The key trade-off is between the number of QPU calls (which increases linearly with the number of clusters) and the embedding quality (which degrades with larger subproblems). For problems requiring more than 100 variables per subproblem, hybrid quantum-classical decomposition methods~\cite{li2025efficient, wang2025quantum} offer a promising path forward, combining quantum annealing for subproblems with classical optimization for coordination.

\paragraph{Scalability Analysis}

The hierarchical method achieves favorable scaling:
\begin{equation}
\text{QPU calls} = K_{\text{coord}} \times \lceil |\mathcal{F}| / 5 \rceil \approx 3 \times F/5 = 0.6F
\end{equation}

compared to clique decomposition's $3F$ calls, achieving a $\sim$5$\times$ reduction in QPU access overhead. The trade-off is larger subproblems requiring non-trivial embedding.

\paragraph{Performance Comparison at 100 Farms}

\begin{table}[H]
\centering
\caption{Decomposition Strategy Performance at 100-Farm Scale}
\label{tab:strategy_comparison}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Strategy} & \textbf{QPU Calls} & \textbf{Embedding Time} & \textbf{Gap (\%)} & \textbf{Violations} \\
\midrule
Clique (farm-by-farm) & 300 & $\sim$0s & 13.8 & 0 \\
Spatial-Temporal & 60 & $\sim$0s & 14.2 & 0 \\
Hierarchical Multi-Level & 60 & 120s & 16.5 & 2 \\
\midrule
D-Wave Hybrid CQM & 1 & N/A & 0.0 & 0 \\
Gurobi (Classical) & -- & -- & 0.0 & 0 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key Observations:}
\begin{itemize}
\item Clique decomposition achieves best pure QPU solution quality but requires most QPU calls.
\item Spatial-temporal reduces calls by 5$\times$ with minimal quality loss.
\item Hierarchical further reduces calls but introduces embedding overhead and minor violations.
\item All strategies achieve solutions within 15--20\% of optimal in tractable time.
\end{itemize}

% =============================================================================
% RESULTS AND CONCLUSIONS SECTION
% =============================================================================
\input{results_and_conclusions}

\end{document}